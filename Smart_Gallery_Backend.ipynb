{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üñºÔ∏è Smart Gallery Backend\n",
        "\n",
        "Production-ready FastAPI backend with:\n",
        "- **YOLO v8** - Object detection\n",
        "- **InsightFace** - Face detection & recognition\n",
        "- **CLIP** - Semantic search\n",
        "\n",
        "Run all cells to start the server with ngrok tunnel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mount Google Drive (optional - for persistent storage)\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install -q fastapi==0.109.2 uvicorn[standard]==0.27.1 python-multipart==0.0.9\n",
        "!pip install -q pydantic==2.6.1 pydantic-settings==2.1.0\n",
        "!pip install -q aiosqlite==0.19.0 sqlalchemy==2.0.25\n",
        "!pip install -q Pillow==10.2.0 opencv-python-headless==4.9.0.80\n",
        "!pip install -q ultralytics==8.1.0\n",
        "!pip install -q insightface==0.7.3 onnxruntime-gpu==1.17.0\n",
        "!pip install -q open-clip-torch==2.24.0\n",
        "!pip install -q faiss-cpu==1.7.4\n",
        "!pip install -q aiofiles==23.2.1 pyngrok==7.0.0\n",
        "print(\"‚úÖ Dependencies installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone or upload the backend code\n",
        "# Option 1: Upload the smart-gallery-backend folder to /content/\n",
        "# Option 2: Clone from GitHub (replace with your repo)\n",
        "# !git clone https://github.com/yourusername/smart-gallery-backend.git /content/smart-gallery-backend\n",
        "\n",
        "import os\n",
        "os.chdir('/content')\n",
        "\n",
        "# Check if backend exists\n",
        "if os.path.exists('/content/smart-gallery-backend'):\n",
        "    print(\"‚úÖ Backend code found!\")\n",
        "else:\n",
        "    print(\"‚ùå Please upload smart-gallery-backend folder to /content/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "import os\n",
        "\n",
        "# Set environment variables\n",
        "os.environ['DEBUG'] = 'false'\n",
        "os.environ['DEVICE'] = 'cuda'  # or 'cpu'\n",
        "\n",
        "# Use Google Drive for persistent storage (optional)\n",
        "# os.environ['DATA_DIR'] = '/content/drive/MyDrive/smart_gallery_data'\n",
        "\n",
        "# Custom YOLO model path (optional)\n",
        "# os.environ['YOLO_MODEL_PATH'] = '/content/drive/MyDrive/models/yolov8x_custom.pt'\n",
        "\n",
        "print(\"‚úÖ Configuration set!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Setup ngrok for public access\n",
        "from pyngrok import ngrok, conf\n",
        "import getpass\n",
        "\n",
        "# Get ngrok auth token\n",
        "print(\"Get your ngrok auth token from: https://dashboard.ngrok.com/get-started/your-authtoken\")\n",
        "NGROK_TOKEN = getpass.getpass(\"Enter ngrok auth token: \")\n",
        "\n",
        "# Configure ngrok\n",
        "conf.get_default().auth_token = NGROK_TOKEN\n",
        "print(\"‚úÖ ngrok configured!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Start the server\n",
        "import sys\n",
        "import asyncio\n",
        "import threading\n",
        "import time\n",
        "\n",
        "sys.path.insert(0, '/content/smart-gallery-backend')\n",
        "\n",
        "def run_server():\n",
        "    import uvicorn\n",
        "    uvicorn.run(\n",
        "        \"app.main:app\",\n",
        "        host=\"0.0.0.0\",\n",
        "        port=8000,\n",
        "        log_level=\"info\"\n",
        "    )\n",
        "\n",
        "# Start server in background thread\n",
        "server_thread = threading.Thread(target=run_server, daemon=True)\n",
        "server_thread.start()\n",
        "\n",
        "# Wait for server to start\n",
        "print(\"‚è≥ Waiting for server to initialize (loading ML models)...\")\n",
        "time.sleep(30)  # Give time for models to load\n",
        "\n",
        "# Start ngrok tunnel\n",
        "public_url = ngrok.connect(8000)\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üöÄ SMART GALLERY API IS RUNNING!\")\n",
        "print(\"=\"*60)\n",
        "print(f\"\\nüåê Public URL: {public_url}\")\n",
        "print(f\"üìö API Docs: {public_url}/docs\")\n",
        "print(f\"\\nüì§ Upload photos via: POST {public_url}/photos/upload\")\n",
        "print(f\"üîç Search photos: GET {public_url}/search/text?q=your+query\")\n",
        "print(\"\\n\" + \"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test the API\n",
        "import requests\n",
        "\n",
        "# Get the ngrok URL\n",
        "url = str(public_url).replace('NgrokTunnel: \"', '').split('\"')[0]\n",
        "\n",
        "# Test health endpoint\n",
        "response = requests.get(f\"{url}/health\")\n",
        "print(\"Health check:\", response.json())\n",
        "\n",
        "# Test stats endpoint\n",
        "response = requests.get(f\"{url}/stats\")\n",
        "print(\"\\nStats:\", response.json())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload a test image\n",
        "import requests\n",
        "from google.colab import files\n",
        "\n",
        "# Upload image from your computer\n",
        "print(\"Select an image to upload:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if uploaded:\n",
        "    filename = list(uploaded.keys())[0]\n",
        "    file_content = uploaded[filename]\n",
        "    \n",
        "    # Upload to API\n",
        "    url = str(public_url).replace('NgrokTunnel: \"', '').split('\"')[0]\n",
        "    response = requests.post(\n",
        "        f\"{url}/photos/upload\",\n",
        "        files={\"files\": (filename, file_content)}\n",
        "    )\n",
        "    \n",
        "    result = response.json()\n",
        "    print(\"\\n‚úÖ Upload result:\")\n",
        "    print(f\"Success: {result['success']}\")\n",
        "    \n",
        "    if result['photos']:\n",
        "        photo = result['photos'][0]\n",
        "        print(f\"\\nPhoto ID: {photo['id']}\")\n",
        "        print(f\"Detections: {len(photo['detections'])} objects\")\n",
        "        print(f\"Faces: {len(photo['faces'])} faces\")\n",
        "        \n",
        "        if photo['detections']:\n",
        "            print(\"\\nDetected objects:\")\n",
        "            for det in photo['detections']:\n",
        "                print(f\"  - {det['class_name']}: {det['confidence']:.2%}\")\n",
        "        \n",
        "        if photo['faces']:\n",
        "            print(\"\\nDetected faces:\")\n",
        "            for face in photo['faces']:\n",
        "                age = face.get('age', 'unknown')\n",
        "                gender = face.get('gender', 'unknown')\n",
        "                print(f\"  - Age: {age}, Gender: {gender}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test semantic search\n",
        "import requests\n",
        "\n",
        "url = str(public_url).replace('NgrokTunnel: \"', '').split('\"')[0]\n",
        "\n",
        "# Search by text\n",
        "query = \"person smiling\"  # Change this to your search query\n",
        "response = requests.get(f\"{url}/search/text\", params={\"q\": query})\n",
        "\n",
        "results = response.json()\n",
        "print(f\"Search results for '{query}':\")\n",
        "print(f\"Found {results['total']} matches\")\n",
        "\n",
        "for r in results['results'][:5]:\n",
        "    print(f\"  - {r['photo']['original_filename']}: {r['similarity']:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Keep the notebook running\n",
        "# The server will stay active as long as this cell is running\n",
        "import time\n",
        "\n",
        "print(\"\\nüü¢ Server is running...\")\n",
        "print(f\"üìç URL: {public_url}\")\n",
        "print(\"\\nPress the stop button to shutdown the server.\")\n",
        "\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(60)\n",
        "        print(\".\", end=\"\", flush=True)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"\\n\\nüõë Server stopped.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
